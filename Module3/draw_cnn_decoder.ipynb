{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOb2WyMdnxkRqUVnTo6hO+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bforoura/GenAI/blob/main/Module3/draw_cnn_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3p_MmKWUThT",
        "outputId": "3be34075-3445-44cd-e914-2de5d755e0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import pydot\n",
        "import graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Define the shape before flattening\n",
        "shape_before_flattening = (4, 4, 128)\n",
        "\n",
        "# Define the input layer\n",
        "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
        "\n",
        "# Define the model for the decoder\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "\n",
        "# Add Conv2DTranspose layers\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3, 3), strides=2, activation='relu', padding='same'\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3, 3), strides=2, activation='relu', padding='same'\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3, 3), strides=2, activation='relu', padding='same'\n",
        ")(x)\n",
        "\n",
        "# Add the final Conv2D layer to produce the output\n",
        "decoder_output = layers.Conv2D(\n",
        "    1, (3, 3), strides=1, activation='sigmoid', padding='same', name='decoder_output'\n",
        ")(x)\n",
        "\n",
        "# Create the decoder model\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "\n",
        "# Plot the model and save it to a PNG file\n",
        "def save_model_as_png(model, filename='model.png'):\n",
        "    # Generate a plot of the model architecture\n",
        "    plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    # Open the generated PNG file and display it (for verification)\n",
        "    img = Image.open('model.png')\n",
        "    img.show()\n",
        "\n",
        "# Save the model diagram directly as a PNG file\n",
        "save_model_as_png(decoder, filename='model.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "nkBk9am1U79j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}